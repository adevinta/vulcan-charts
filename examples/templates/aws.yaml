---
# Source: vulcan/templates/api/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: myrelease-vulcan-api
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: api
type: Opaque
data:
  PG_PASSWORD: "cGFzc3dvcmRkYmFwaQ=="
  SECRET_KEY: "YXBpc2VjcmV0a2V5"
  AWSCATALOGUE_KEY: "YXdzY2F0YWxvZ2VrZXk="
---
# Source: vulcan/templates/crontinuous/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: myrelease-vulcan-crontinuous
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: crontinuous
type: Opaque
data:
  VULCAN_TOKEN: "c3VwZXJzZWNyZXR2dWxjYW50b2tlbg=="
---
# Source: vulcan/templates/dogstatsd-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: myrelease-vulcan-dogstatsd
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: dogstatsd
type: Opaque
data:
  DD_API_KEY: "eHh4eHh4eHh4eHh4eHh4eHh4eHh4"
---
# Source: vulcan/templates/metrics/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: myrelease-vulcan-metrics
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: metrics
type: Opaque
data:
  DEVHOSE_TOKEN: "c2VjcmV0ZGV2aG9zZXRva2Vu"
  VULCAN_API_TOKEN: "c3VwZXJzZWNyZXR2dWxjYW50b2tlbg=="
---
# Source: vulcan/templates/persistence/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: myrelease-vulcan-persistence
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: persistence
type: Opaque
data:
  POSTGRES_PASSWORD: "cGFzc3dvcmRwZXJzaXN0ZW5jZQ=="
  SECRET_KEY_BASE: "c2VjcmV0a2V5"
---
# Source: vulcan/templates/reportsgenerator/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: myrelease-vulcan-reportsgenerator
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: reportsgenerator
type: Opaque
data:
  PG_PASSWORD: "cGFzc3dvcmRyZXBvcnRnZW5lcmF0b3I="
---
# Source: vulcan/templates/scanengine/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: myrelease-vulcan-scanengine
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: scanengine
type: Opaque
data:
  PG_PASSWORD: "cGFzc3dvcmRzY2FuZW5naW5l"
---
# Source: vulcan/templates/stream/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: myrelease-vulcan-stream
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: stream
type: Opaque
data:
  REDIS_PWD: "bXllbGFzdGljcHdk"
---
# Source: vulcan/templates/vulndb/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: myrelease-vulcan-vulndb
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vulndb
type: Opaque
data:
  PG_PASSWORD: "eHh4eHh4eHh4eA=="
---
# Source: vulcan/templates/vulndbapi/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: myrelease-vulcan-vulndbapi
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vulndbapi
type: Opaque
data:
  PG_PASSWORD: "eHh4eHh4eHh4eA=="
---
# Source: vulcan/templates/api/deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myrelease-vulcan-api-proxy
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: api
data:
  haproxy.cfg: |
    global
      daemon
      maxconn 64
      log stdout format raw daemon

    defaults
      mode http
      timeout connect 5s
      timeout client 25s
      timeout server 50s
      timeout tunnel 3600s
      option  http-server-close

    frontend http
      bind *:9090
      log global
      option httplog clf
      http-request capture req.hdr(Host) len 50
      http-request capture req.hdr(User-Agent) len 100

      default_backend app

    backend app
      server app 127.0.0.1:8080

    frontend stats
      bind *:9101
      option http-use-htx
      http-request use-service prometheus-exporter if { path /metrics }
      monitor-uri /healthz
---
# Source: vulcan/templates/crontinuous/deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myrelease-vulcan-crontinuous-proxy
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: crontinuous
data:
  haproxy.cfg: |
    global
      daemon
      maxconn 64
      log stdout format raw daemon

    defaults
      mode http
      timeout connect 5s
      timeout client 25s
      timeout server 25s
      timeout tunnel 3600s
      option  http-server-close

    frontend http
      bind *:9090
      log global
      option httplog clf
      http-request capture req.hdr(Host) len 50
      http-request capture req.hdr(User-Agent) len 100

      default_backend app

    backend app
      server app 127.0.0.1:8080

    frontend stats
      bind *:9101
      option http-use-htx
      http-request use-service prometheus-exporter if { path /metrics }
      monitor-uri /healthz
---
# Source: vulcan/templates/extra-manifests.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
  name: vulcan-custom-configmap
data:
  custom.cfg: |
    Example file
---
# Source: vulcan/templates/insights/config-proxy.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myrelease-vulcan-insights-proxy
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: insights
data:
  haproxy.cfg: |
    global
      daemon
      maxconn 64
      log stdout format raw daemon

    defaults
      mode http
      timeout connect 5s
      timeout client 25s
      timeout server 25s
      timeout tunnel 3600s
      option  http-server-close
    cache small
      total-max-size 64     # mb
      max-age 240           # seconds

    frontend http
      bind *:9090
      log global
      option httplog clf
      http-request cache-use small
      http-response cache-store small
      http-request capture req.hdr(Host) len 50
      http-request capture req.hdr(User-Agent) len 100
      default_backend private
      use_backend public if { path -i -m beg /public }

    backend private
      server app 127.0.0.1:8080

    backend public
      server app 127.0.0.1:8081

    frontend stats
      bind *:9101
      option http-use-htx
      http-request use-service prometheus-exporter if { path /metrics }
      monitor-uri /healthz
---
# Source: vulcan/templates/persistence/deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myrelease-vulcan-persistence-proxy
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: persistence
data:
  haproxy.cfg: |
    global
      daemon
      maxconn 64
      log stdout format raw daemon

    defaults
      mode http
      timeout connect 5s
      timeout client 25s
      timeout server 25s
      timeout tunnel 3600s
      option  http-server-close

    frontend http
      bind *:9090
      log global
      option httplog clf
      http-request capture req.hdr(Host) len 50
      http-request capture req.hdr(User-Agent) len 100

      default_backend app

    backend app
      server app 127.0.0.1:8080

    frontend stats
      bind *:9101
      option http-use-htx
      http-request use-service prometheus-exporter if { path /metrics }
      monitor-uri /healthz
---
# Source: vulcan/templates/reportsgenerator/deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myrelease-vulcan-reportsgenerator-proxy
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: reportsgenerator
data:
  haproxy.cfg: |
    global
      daemon
      maxconn 64
      log stdout format raw daemon

    defaults
      mode http
      timeout connect 5s
      timeout client 25s
      timeout server 25s
      timeout tunnel 3600s
      option  http-server-close

    frontend http
      bind *:9090
      log global
      option httplog clf
      http-request capture req.hdr(Host) len 50
      http-request capture req.hdr(User-Agent) len 100

      default_backend app

    backend app
      server app 127.0.0.1:8080

    frontend stats
      bind *:9101
      option http-use-htx
      http-request use-service prometheus-exporter if { path /metrics }
      monitor-uri /healthz
---
# Source: vulcan/templates/results/deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myrelease-vulcan-results-proxy
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: results
data:
  haproxy.cfg: |
    global
      daemon
      maxconn 64
      log stdout format raw daemon

    defaults
      mode http
      timeout connect 5s
      timeout client 25s
      timeout server 25s
      timeout tunnel 3600s
      option  http-server-close

    frontend http
      bind *:9090
      log global
      option httplog clf
      http-request capture req.hdr(Host) len 50
      http-request capture req.hdr(User-Agent) len 100

      default_backend app

    backend app
      server app 127.0.0.1:8080

    frontend stats
      bind *:9101
      option http-use-htx
      http-request use-service prometheus-exporter if { path /metrics }
      monitor-uri /healthz
---
# Source: vulcan/templates/scanengine/deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myrelease-vulcan-scanengine-proxy
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: scanengine
data:
  haproxy.cfg: |
    global
      daemon
      maxconn 64
      log stdout format raw daemon

    defaults
      mode http
      timeout connect 5s
      timeout client 25s
      timeout server 25s
      timeout tunnel 3600s
      option  http-server-close

    frontend http
      bind *:9090
      log global
      option httplog clf
      http-request capture req.hdr(Host) len 50
      http-request capture req.hdr(User-Agent) len 100

      default_backend app

    backend app
      server app 127.0.0.1:8080

    frontend stats
      bind *:9101
      option http-use-htx
      http-request use-service prometheus-exporter if { path /metrics }
      monitor-uri /healthz
---
# Source: vulcan/templates/stream/deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myrelease-vulcan-stream-proxy
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: stream
data:
  haproxy.cfg: |
    global
      daemon
      maxconn 64
      log stdout format raw daemon

    defaults
      mode http
      timeout connect 5s
      timeout client 25s
      timeout server 25s
      timeout tunnel 3600s
      option  http-server-close

    frontend http
      bind *:9090
      log global
      option httplog clf
      http-request capture req.hdr(Host) len 50
      http-request capture req.hdr(User-Agent) len 100

      default_backend app

    backend app
      server app 127.0.0.1:8080

    frontend stats
      bind *:9101
      option http-use-htx
      http-request use-service prometheus-exporter if { path /metrics }
      monitor-uri /healthz
---
# Source: vulcan/templates/ui/deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myrelease-vulcan-ui-proxy
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ui
data:
  haproxy.cfg: |
    global
      daemon
      maxconn 64
      log stdout format raw daemon

    defaults
      mode http
      timeout connect 5s
      timeout client 25s
      timeout server 25s
      timeout tunnel 3600s
      option  http-server-close

    frontend http
      bind *:9090
      log global
      option httplog clf
      http-request capture req.hdr(Host) len 50
      http-request capture req.hdr(User-Agent) len 100

      default_backend app

    backend app
      server app 127.0.0.1:8080

    frontend stats
      bind *:9101
      option http-use-htx
      http-request use-service prometheus-exporter if { path /metrics }
      monitor-uri /healthz
---
# Source: vulcan/templates/vulndbapi/deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myrelease-vulcan-vulndbapi-proxy
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vulndbapi
data:
  haproxy.cfg: |
    global
      daemon
      maxconn 64
      log stdout format raw daemon

    defaults
      mode http
      timeout connect 5s
      timeout client 25s
      timeout server 25s
      timeout tunnel 3600s
      option  http-server-close
    cache small
      total-max-size 64     # mb
      max-age 600           # seconds

    frontend http
      bind *:9090
      log global
      option httplog clf
      http-request cache-use small
      http-response cache-store small
      http-request capture req.hdr(Host) len 50
      http-request capture req.hdr(User-Agent) len 100

      default_backend app

    backend app
      server app 127.0.0.1:8080

    frontend stats
      bind *:9101
      option http-use-htx
      http-request use-service prometheus-exporter if { path /metrics }
      monitor-uri /healthz
---
# Source: vulcan/templates/api/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myrelease-vulcan-api
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: api
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/name: api
---
# Source: vulcan/templates/crontinuous/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myrelease-vulcan-crontinuous
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: crontinuous
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/name: crontinuous
---
# Source: vulcan/templates/insights/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myrelease-vulcan-insights
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: insights
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/name: insights
---
# Source: vulcan/templates/persistence/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myrelease-vulcan-persistence
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: persistence
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/name: persistence
---
# Source: vulcan/templates/reportsgenerator/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myrelease-vulcan-reportsgenerator
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: reportsgenerator
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/name: reportsgenerator
---
# Source: vulcan/templates/results/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myrelease-vulcan-results
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: results
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/name: results
---
# Source: vulcan/templates/scanengine/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myrelease-vulcan-scanengine
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: scanengine
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/name: scanengine
---
# Source: vulcan/templates/stream/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myrelease-vulcan-stream
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: stream
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/name: stream
---
# Source: vulcan/templates/ui/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myrelease-vulcan-ui
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ui
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/name: ui
---
# Source: vulcan/templates/vulndbapi/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myrelease-vulcan-vulndbapi
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vulndbapi
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/name: vulndbapi
---
# Source: vulcan/templates/api/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myrelease-vulcan-api
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: api
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: vulcan
      app.kubernetes.io/name: api
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vulcan
        global-label: foo
        global-namespace: 'ns'
        extra-label-tag: api-tag-api
        app.kubernetes.io/name: api
      annotations:
        checksum/secrets: 4b2965d6cd7e00abfdbc0ddaa04efd8c79ee2589623880718d967a9193b18db5
        checksum/config-proxy: b1f79511df902d1c4f4aa250877668b3fc2eca6fc53c05b92c903db991e56e8c
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9101'
        iam.amazonaws.com/role: arn:aws:iam::000000000000:role/APIRole
    spec:
      initContainers:
        - name: waitfordb
          image: "busybox:1.34.1"
          imagePullPolicy: Always
          command: ['sh', '-c', 'until nc -z "$PGHOST" "$PGPORT"; do echo WaitingDB && sleep 5; done;']
          env:
          - name: PGHOST
            value: "api.postgres.host"
          - name: PGPORT
            value: "5432"
      containers:
        
        - name: dogstatsd
          image: "datadog/dogstatsd:7.32.3"
          envFrom:
          - secretRef:
              name: myrelease-vulcan-dogstatsd
          ports:
            - containerPort: 8125
              name: dogstatsd
              protocol: UDP
        - name: proxy
          image: "haproxy:2.3.16-alpine3.15"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9090
            - name: metrics
              containerPort: 9101
          volumeMounts:
          - mountPath: /usr/local/etc/haproxy
            readOnly: true
            name: config-proxy
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
        - name: api
          
          image: "adevinta/vulcan-api:tag-api"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          livenessProbe:
            httpGet:
              path: /api/v1/healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 10
          readinessProbe:
            httpGet:
              path: /api/v1/healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 5
          env:
          - name: PORT
            value: "8080"
          - name: PG_HOST
            value: "api.postgres.host"
          - name: PG_NAME
            value: "vulcanapi"
          - name: PG_USER
            value: "vulcan"
          - name: PG_PORT
            value: "5432"
          - name: PG_SSLMODE
            value: "verify-full"
          - name: PG_CA_B64
            value: "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVCakNDQXU2Z0F3SUJBZ0lKQU1jMFp6YVNVSzUxTUEwR0NTcUdTSWIzRFFFQkN3VUFNSUdQTVFzd0NRWUQKVlFRR0V3SlZVekVRTUE0R0ExVUVCd3dIVTJWaGRIUnNaVEVUTUJFR0ExVUVDQXdLVjJGemFHbHVaM1J2YmpFaQpNQ0FHQTFVRUNnd1pRVzFoZW05dUlGZGxZaUJUWlhKMmFXTmxjeXdnU1c1akxqRVRNQkVHQTFVRUN3d0tRVzFoCmVtOXVJRkpFVXpFZ01CNEdBMVVFQXd3WFFXMWhlbTl1SUZKRVV5QlNiMjkwSURJd01Ua2dRMEV3SGhjTk1Ua3cKT0RJeU1UY3dPRFV3V2hjTk1qUXdPREl5TVRjd09EVXdXakNCanpFTE1Ba0dBMVVFQmhNQ1ZWTXhFREFPQmdOVgpCQWNNQjFObFlYUjBiR1V4RXpBUkJnTlZCQWdNQ2xkaGMyaHBibWQwYjI0eElqQWdCZ05WQkFvTUdVRnRZWHB2CmJpQlhaV0lnVTJWeWRtbGpaWE1zSUVsdVl5NHhFekFSQmdOVkJBc01Da0Z0WVhwdmJpQlNSRk14SURBZUJnTlYKQkFNTUYwRnRZWHB2YmlCU1JGTWdVbTl2ZENBeU1ERTVJRU5CTUlJQklqQU5CZ2txaGtpRzl3MEJBUUVGQUFPQwpBUThBTUlJQkNnS0NBUUVBclhuRi9FNi9RaCtrdTNoUVRTS1BNaFFRbENwb1d2bkl0aHpYNk1LM3A1YTBlWEtaCm9XSWpZY05ORzZVd0pqcDRmVVhsNmdscDUzSm9ibit0V05YODhkTkgybjhEVmJwcFN3U2NWRTJMcHVMKzk0dlkKMEVZRS9YeE43c3ZLZWE4WXZscnFrVUJLeXhMeFRqaCtVL0tyR09hSHh6OXYwbDZaTmxEYnVhWnczcUlXZEQvSQo2YU5iR2VSVVZ0cE02UCtiV0lveFZsL2NhUXlsUVM2Q0VZVWsrQ3BWeUpTa29wd0pselhUMDd0TW9ETDVXZ1g5Ck8wOEtWZ0ROejlxUC9JR3RBY1JkdVJjTmlvSDNFOXY5ODFRTzF6dC9HcGIyZjhOcUFqVVVDVVp6T25pajZteDkKTWNaKzljV1g4OENSelIwdlFPRFd1WnNjZ0kwOE52TTY5Rm4yU1FJREFRQUJvMk13WVRBT0JnTlZIUThCQWY4RQpCQU1DQVFZd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVWMxOWcyTHpMQTVqMEt4YzBMalphCnBtRC92Qjh3SHdZRFZSMGpCQmd3Rm9BVWMxOWcyTHpMQTVqMEt4YzBMalphcG1EL3ZCOHdEUVlKS29aSWh2Y04KQVFFTEJRQURnZ0VCQUhBRzdXVG15anpQUklNODVyVmorZldIc0xJdnFwdzZET2JJak1Xb2twbGlDZU1JTlpGVgp5bmZnQktzZjFFeHdidkpOellGWFc2ZGlobmd1REc5Vk1QcGkydXAvY3RRVE44dG05bkRLT3kwOHVOWm9vZk1jCk5VWnhLQ0VrVktaditJTDRvSG9lYXl0OGVndHYzdWpKTTZWMTRBc3RNUTZTd3Z3dkE5M0VQL1VnMmU0V0FYSHUKY2JJMU5BYlVnVkRxcCtEUmRmdlprZ1lLcnlqVFdkLzArMWZTOFgxYkJaVld6bDdlaXJOVm5IYlNIMlpEcE51WQowU0JkOGRqNUY2bGQzdDU4eWRaYnJUSHplN0pKT2Q4aWp5U0FwNC9raXU5VWZaV3VUUEFCekRhL0RTZHo5RGsvCnpQVzRDWFh2aExtRTAyVEE5L0hlQ3czS0VISXdpY051RWZ3PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg=="
          - name: LOG_LEVEL
            value: "INFO"
          - name: COOKIE_DOMAIN
            value: "example.vulcan.com"
          - name: SAML_MEATADATA
            value: "https://org.issuer.com/app/appcode/sso/saml/metadata"
          - name: SAML_ISSUER
            value: "http://www.issuer.com/appcode"
          - name: SAML_CALLBACK
            value: "https://www.vulcan.example.com/api/v1/login/callback"
          - name: SAML_TRUSTED_DOMAINS
            value: "[\"vulcan.example.com\"]"
          - name: DEFAULT_OWNERS
            value: "[\"aaaaaaaa-xxxx-yyyy-zzzz-bbbbbbbbbbbb\"]"
          - name: SCANENGINE_URL
            value: "http://myrelease-vulcan-scanengine/v1/"
          - name: SCHEDULER_URL
            value: "http://myrelease-vulcan-crontinuous/"
          - name: SQS_QUEUE_ARN
            value: "arn:aws:sqs:eu-west-1:000000000000:APIScans"
          - name: REPORTS_SNS_ARN
            value: "arn:aws:sns:eu-west-1:000000000000:ReportsGen"
          - name: REPORTS_API_URL
            value: "http://myrelease-vulcan-reportsgenerator/"
          - name: SCAN_REDIRECT_URL
            value: 
          - name: VULCAN_UI_URL
            value: "https://www.vulcan.example.com"
          - name: PERSISTENCE_HOST
            value: "myrelease-vulcan-persistence"
          - name: VULNERABILITYDB_URL
            value: "http://myrelease-vulcan-vulndbapi/"
          - name: AWSCATALOGUE_KIND
            value: "CloudGovernance"
          - name: AWSCATALOGUE_URL
            value: "https://catalogue-api.host"
          - name: AWSCATALOGUE_RETRIES
            value: "4"
          - name: AWSCATALOGUE_RETRY_INTERVAL
            value: "2"
          
          - name: DOGSTATSD_ENABLED
            value: "true"
          - name: DOGSTATSD_HOST
            value: "localhost"
          - name: DOGSTATSD_PORT
            value: "8125"
          envFrom:
          - secretRef:
              name: myrelease-vulcan-api
          ports:
            - name: app
              containerPort: 8080
              protocol: TCP
      volumes:
      - name: config-proxy
        configMap:
          name: myrelease-vulcan-api-proxy
      
      imagePullSecrets:
        - name: pullsecretname
---
# Source: vulcan/templates/crontinuous/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myrelease-vulcan-crontinuous
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: crontinuous
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: vulcan
      app.kubernetes.io/name: crontinuous
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vulcan
        global-label: foo
        global-namespace: 'ns'
        extra-label: crontinuous
        app.kubernetes.io/name: crontinuous
      annotations:
        checksum/secrets: 52a4bbb1036776d3303684f3b0b145564cc29d64a24d08e0c4cfe1b0301da0e0
        checksum/config-proxy: 27abd719fb6539a43df4feedc270a6cc76d5046c5ccd1cf1be05850a328547b6
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9101'
        iam.amazonaws.com/role: arn:aws:iam::000000000000:role/CrontinuousRole
    spec:
      containers:
        
        - name: proxy
          image: "haproxy:2.3.16-alpine3.15"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9090
            - name: metrics
              containerPort: 9101
          volumeMounts:
          - mountPath: /usr/local/etc/haproxy
            readOnly: true
            name: config-proxy
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
        - name: crontinuous
          
          image: "adevinta/vulcan-crontinuous:tag-crontinuous"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          livenessProbe:
            httpGet:
              path: /healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 10
          readinessProbe:
            httpGet:
              path: /healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 5
          env:
          - name: PORT
            value: "8080"
          - name: AWS_REGION
            value: eu-west-1
          - name: CRONTINUOUS_BUCKET
            value: s3-vulcan-crontinuous
          - name: VULCAN_API
            value: http://myrelease-vulcan-api/api
          - name: VULCAN_USER
            value: vulcanuser
          - name: ENABLE_TEAMS_WHITELIST_SCAN
            value: "false"
          - name: TEAMS_WHITELIST_SCAN
            value: "[]"
          - name: ENABLE_TEAMS_WHITELIST_REPORT
            value: "false"
          - name: TEAMS_WHITELIST_REPORT
            value: "[]"
          
          
          envFrom:
          - secretRef:
              name: myrelease-vulcan-crontinuous
          ports:
            - name: app
              containerPort: 8080
              protocol: TCP
      volumes:
      - name: config-proxy
        configMap:
          name: myrelease-vulcan-crontinuous-proxy
      
      imagePullSecrets:
        - name: pullsecretname
---
# Source: vulcan/templates/insights/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myrelease-vulcan-insights
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: insights
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: vulcan
      app.kubernetes.io/name: insights
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vulcan
        global-label: foo
        global-namespace: 'ns'
        app.kubernetes.io/name: insights
      annotations:
        checksum/config: 14cca85adc5744b6bc619ef4c5c8a08066862fe9a1eb6706a99ddf80ee1ea607
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9101'
        iam.amazonaws.com/role: arn:aws:iam::000000000000:role/InsightsRole
    spec:
      containers:
        
        - name: proxy
          image: "haproxy:2.3.16-alpine3.15"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9090
            - name: metrics
              containerPort: 9101
          volumeMounts:
          - mountPath: /usr/local/etc/haproxy
            readOnly: true
            name: config-proxy
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
        - name: insights-private
          
          image: "pottava/s3-proxy:2.0"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          livenessProbe:
            httpGet:
              path: /healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 10
          readinessProbe:
            httpGet:
              path: /healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 5
          env:
            - name: AWS_REGION
              value: "eu-west-1"
            - name: ACCESS_LOG
              value: "false"
            - name: AWS_S3_BUCKET
              value: "s3-vulcan-insights"
            - name: STRIP_PATH
              value: ""
            - name: HEALTHCHECK_PATH
              value: "/healthcheck"
            - name: APP_PORT
              value: "8080"
          ports:
            - name: private
              containerPort: 8080
              protocol: TCP
        - name: insights-public
          
          image: "pottava/s3-proxy:2.0"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          livenessProbe:
            httpGet:
              path: /healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 10
          readinessProbe:
            httpGet:
              path: /healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 5
          env:
            - name: AWS_REGION
              value: "eu-west-1"
            - name: ACCESS_LOG
              value: "false"
            - name: AWS_S3_BUCKET
              value: "s3-vulcan-public-insights"
            - name: STRIP_PATH
              value: "/public"
            - name: HEALTHCHECK_PATH
              value: "/healthcheck"
            - name: APP_PORT
              value: "8081"
          ports:
            - name: private
              containerPort: 8081
              protocol: TCP
      volumes:
      - name: config-proxy
        configMap:
          name: myrelease-vulcan-insights-proxy
---
# Source: vulcan/templates/metrics/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myrelease-vulcan-metrics
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: metrics
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: vulcan
      app.kubernetes.io/name: metrics
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vulcan
        global-label: foo
        global-namespace: 'ns'
        app.kubernetes.io/name: metrics
      annotations:
        
        iam.amazonaws.com/role: arn:aws:iam::000000000000:role/MetricsRole
    spec:
      containers:
        
        - name: dogstatsd
          image: "datadog/dogstatsd:7.32.3"
          envFrom:
          - secretRef:
              name: myrelease-vulcan-dogstatsd
          ports:
            - containerPort: 8125
              name: dogstatsd
              protocol: UDP
        - name: redis
          image: "bitnami/redis:6.2.6"
          env:
          - name: ALLOW_EMPTY_PASSWORD
            value: "yes"
          ports:
          - containerPort: 6379
            name: redis
            protocol: TCP
        - name: metrics
          
          image: "containers.mpi-internal.com/spt-security/vulcan-metrics:tag-metrics"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          env:
          - name: LOG_LEVEL
            value: "warn"
          - name: SQS_POLLING_INTERVAL
            value: "10"
          - name: CHECKS_SQS_QUEUE_ARN
            value: "arn:aws:sqs:eu-west-1:000000000000:MetricsChecks"
          - name: SCANS_SQS_QUEUE_ARN
            value: "arn:aws:sqs:eu-west-1:000000000000:MetricsScans"
          - name: FINDINGS_SQS_QUEUE_ARN
            value: "arn:aws:sqs:eu-west-1:000000000000:MetricsFindings"
          - name: RESULTS_HOST
            value: "myrelease-vulcan-results"
          - name: RESULTS_SCHEME
            value: "http"
          - name: DEVHOSE_URL
            value: "http://devhosehost.com/devhose"
          - name: DEVHOSE_TENANT
            value: "purple"
          - name: DEVHOSE_METRICS_SOURCE
            value: "usage"
          - name: DEVHOSE_FINDINGS_SOURCE
            value: "vulcan-findings"
          - name: REDIS_ADDR
            value: "localhost:6379"
          - name: VULCAN_API
            value: http://myrelease-vulcan-api/api
          - name: VULCAN_API_EXTERNAL
            value: "https://api.vulcan.example.com/api"
          
          - name: DOGSTATSD_ENABLED
            value: "true"
          - name: DOGSTATSD_HOST
            value: "localhost"
          - name: DOGSTATSD_PORT
            value: "8125"
          envFrom:
          - secretRef:
              name: myrelease-vulcan-metrics
      volumes:
      
      
      imagePullSecrets:
        - name: pullsecretname
---
# Source: vulcan/templates/persistence/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myrelease-vulcan-persistence
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: persistence
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: vulcan
      app.kubernetes.io/name: persistence
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vulcan
        global-label: foo
        global-namespace: 'ns'
        app.kubernetes.io/name: persistence
      annotations:
        checksum/secrets: 54e032d49a60159de771c210e9b7224dc3009267d153a4cedb37f39d374fe372
        checksum/config-proxy: 13201ad7fd1d4e84da810c0bbe2c5daf7277e96115558005c513ec2a19e0ee48
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9101'
        iam.amazonaws.com/role: arn:aws:iam::000000000000:role/PersistenceRole
    spec:
      initContainers:
        - name: waitfordb
          image: "busybox:1.34.1"
          imagePullPolicy: Always
          command: ['sh', '-c', 'until nc -z "$PGHOST" "$PGPORT"; do echo WaitingDB && sleep 5; done;']
          env:
          - name: PGHOST
            value: "persistence.postgres.host"
          - name: PGPORT
            value: "5432"
      containers:
        
        - name: dogstatsd
          image: "datadog/dogstatsd:7.32.3"
          envFrom:
          - secretRef:
              name: myrelease-vulcan-dogstatsd
          ports:
            - containerPort: 8125
              name: dogstatsd
              protocol: UDP
        - name: proxy
          image: "haproxy:2.3.16-alpine3.15"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9090
            - name: metrics
              containerPort: 9101
          volumeMounts:
          - mountPath: /usr/local/etc/haproxy
            readOnly: true
            name: config-proxy
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
        - name: persistence
          
          image: "adevinta/vulcan-persistence:tag-persistence"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          livenessProbe:
            httpGet:
              path: /status
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 10
          readinessProbe:
            httpGet:
              path: /status
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 5
          env:
          - name: PORT
            value: "8080"
          - name: POSTGRES_HOST
            value: "persistence.postgres.host"
          - name: POSTGRES_DB
            value: "vulcanpersistence"
          - name: POSTGRES_USER
            value: "vulcan"
          - name: POSTGRES_PORT
            value: "5432"
          - name: POSTGRES_SSLMODE
            value: "verify-full"
          - name: POSTGRES_CA_B64
            value: "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVCakNDQXU2Z0F3SUJBZ0lKQU1jMFp6YVNVSzUxTUEwR0NTcUdTSWIzRFFFQkN3VUFNSUdQTVFzd0NRWUQKVlFRR0V3SlZVekVRTUE0R0ExVUVCd3dIVTJWaGRIUnNaVEVUTUJFR0ExVUVDQXdLVjJGemFHbHVaM1J2YmpFaQpNQ0FHQTFVRUNnd1pRVzFoZW05dUlGZGxZaUJUWlhKMmFXTmxjeXdnU1c1akxqRVRNQkVHQTFVRUN3d0tRVzFoCmVtOXVJRkpFVXpFZ01CNEdBMVVFQXd3WFFXMWhlbTl1SUZKRVV5QlNiMjkwSURJd01Ua2dRMEV3SGhjTk1Ua3cKT0RJeU1UY3dPRFV3V2hjTk1qUXdPREl5TVRjd09EVXdXakNCanpFTE1Ba0dBMVVFQmhNQ1ZWTXhFREFPQmdOVgpCQWNNQjFObFlYUjBiR1V4RXpBUkJnTlZCQWdNQ2xkaGMyaHBibWQwYjI0eElqQWdCZ05WQkFvTUdVRnRZWHB2CmJpQlhaV0lnVTJWeWRtbGpaWE1zSUVsdVl5NHhFekFSQmdOVkJBc01Da0Z0WVhwdmJpQlNSRk14SURBZUJnTlYKQkFNTUYwRnRZWHB2YmlCU1JGTWdVbTl2ZENBeU1ERTVJRU5CTUlJQklqQU5CZ2txaGtpRzl3MEJBUUVGQUFPQwpBUThBTUlJQkNnS0NBUUVBclhuRi9FNi9RaCtrdTNoUVRTS1BNaFFRbENwb1d2bkl0aHpYNk1LM3A1YTBlWEtaCm9XSWpZY05ORzZVd0pqcDRmVVhsNmdscDUzSm9ibit0V05YODhkTkgybjhEVmJwcFN3U2NWRTJMcHVMKzk0dlkKMEVZRS9YeE43c3ZLZWE4WXZscnFrVUJLeXhMeFRqaCtVL0tyR09hSHh6OXYwbDZaTmxEYnVhWnczcUlXZEQvSQo2YU5iR2VSVVZ0cE02UCtiV0lveFZsL2NhUXlsUVM2Q0VZVWsrQ3BWeUpTa29wd0pselhUMDd0TW9ETDVXZ1g5Ck8wOEtWZ0ROejlxUC9JR3RBY1JkdVJjTmlvSDNFOXY5ODFRTzF6dC9HcGIyZjhOcUFqVVVDVVp6T25pajZteDkKTWNaKzljV1g4OENSelIwdlFPRFd1WnNjZ0kwOE52TTY5Rm4yU1FJREFRQUJvMk13WVRBT0JnTlZIUThCQWY4RQpCQU1DQVFZd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVWMxOWcyTHpMQTVqMEt4YzBMalphCnBtRC92Qjh3SHdZRFZSMGpCQmd3Rm9BVWMxOWcyTHpMQTVqMEt4YzBMalphcG1EL3ZCOHdEUVlKS29aSWh2Y04KQVFFTEJRQURnZ0VCQUhBRzdXVG15anpQUklNODVyVmorZldIc0xJdnFwdzZET2JJak1Xb2twbGlDZU1JTlpGVgp5bmZnQktzZjFFeHdidkpOellGWFc2ZGlobmd1REc5Vk1QcGkydXAvY3RRVE44dG05bkRLT3kwOHVOWm9vZk1jCk5VWnhLQ0VrVktaditJTDRvSG9lYXl0OGVndHYzdWpKTTZWMTRBc3RNUTZTd3Z3dkE5M0VQL1VnMmU0V0FYSHUKY2JJMU5BYlVnVkRxcCtEUmRmdlprZ1lLcnlqVFdkLzArMWZTOFgxYkJaVld6bDdlaXJOVm5IYlNIMlpEcE51WQowU0JkOGRqNUY2bGQzdDU4eWRaYnJUSHplN0pKT2Q4aWp5U0FwNC9raXU5VWZaV3VUUEFCekRhL0RTZHo5RGsvCnpQVzRDWFh2aExtRTAyVEE5L0hlQ3czS0VISXdpY051RWZ3PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg=="
          - name: LOG_LEVEL
            value: "info"
          - name: RAILS_MAX_THREADS
            value: "16"
          
          - name: DOGSTATSD_ENABLED
            value: "true"
          - name: DOGSTATSD_HOST
            value: "localhost"
          - name: DOGSTATSD_PORT
            value: "8125"
          envFrom:
          - secretRef:
              name: myrelease-vulcan-persistence
          ports:
            - name: app
              containerPort: 8080
              protocol: TCP
      volumes:
      - name: config-proxy
        configMap:
          name: myrelease-vulcan-persistence-proxy
      
      imagePullSecrets:
        - name: pullsecretname
---
# Source: vulcan/templates/reportsgenerator/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myrelease-vulcan-reportsgenerator
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: reportsgenerator
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: vulcan
      app.kubernetes.io/name: reportsgenerator
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vulcan
        global-label: foo
        global-namespace: 'ns'
        app.kubernetes.io/name: reportsgenerator
      annotations:
        checksum/secrets: cbe2a3f7f759c0ae7d4bfabeaec2bbe97bc12c27bba19be8983c3bf56a094f46
        checksum/config-proxy: 915adf097de54ec18ddfcbb8c7e03a86d99cfa787ce4d7c76ec5d76b8daad4ba
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9101'
        iam.amazonaws.com/role: arn:aws:iam::000000000000:role/ReportsGeneratorRole
    spec:
      initContainers:
        - name: waitfordb
          image: "busybox:1.34.1"
          imagePullPolicy: Always
          command: ['sh', '-c', 'until nc -z "$PGHOST" "$PGPORT"; do echo WaitingDB && sleep 5; done;']
          env:
          - name: PGHOST
            value: "reportsgenerator.postgres.host"
          - name: PGPORT
            value: "5432"
      containers:
        
        - name: dogstatsd
          image: "datadog/dogstatsd:7.32.3"
          envFrom:
          - secretRef:
              name: myrelease-vulcan-dogstatsd
          ports:
            - containerPort: 8125
              name: dogstatsd
              protocol: UDP
          resources:
                    limits:
                      cpu: 100m
                      memory: 128Mi
                    requests:
                      cpu: 100m
                      memory: 128Mi
        - name: proxy
          image: "haproxy:2.3.16-alpine3.15"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9090
            - name: metrics
              containerPort: 9101
          volumeMounts:
          - mountPath: /usr/local/etc/haproxy
            readOnly: true
            name: config-proxy
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          resources:
            limits:
              cpu: 100m
              memory: 128Mi
            requests:
              cpu: 100m
              memory: 128Mi
        - name: reportsgenerator
          
          image: "adevinta/vulcan-reports-generator:tag-reports"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          livenessProbe:
            httpGet:
              path: /healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 10
          readinessProbe:
            httpGet:
              path: /healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 5
          resources:
            limits:
              cpu: 250m
              memory: 2Gi
            requests:
              cpu: 250m
              memory: 2Gi
          env:
          - name: PORT
            value: "8080"
          - name: PG_HOST
            value: "reportsgenerator.postgres.host"
          - name: PG_NAME
            value: "reportsgenerator"
          - name: PG_USER
            value: "vulcan"
          - name: PG_PORT
            value: "5432"
          - name: PG_SSLMODE
            value: "verify-full"
          - name: PG_CA_B64
            value: "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVCakNDQXU2Z0F3SUJBZ0lKQU1jMFp6YVNVSzUxTUEwR0NTcUdTSWIzRFFFQkN3VUFNSUdQTVFzd0NRWUQKVlFRR0V3SlZVekVRTUE0R0ExVUVCd3dIVTJWaGRIUnNaVEVUTUJFR0ExVUVDQXdLVjJGemFHbHVaM1J2YmpFaQpNQ0FHQTFVRUNnd1pRVzFoZW05dUlGZGxZaUJUWlhKMmFXTmxjeXdnU1c1akxqRVRNQkVHQTFVRUN3d0tRVzFoCmVtOXVJRkpFVXpFZ01CNEdBMVVFQXd3WFFXMWhlbTl1SUZKRVV5QlNiMjkwSURJd01Ua2dRMEV3SGhjTk1Ua3cKT0RJeU1UY3dPRFV3V2hjTk1qUXdPREl5TVRjd09EVXdXakNCanpFTE1Ba0dBMVVFQmhNQ1ZWTXhFREFPQmdOVgpCQWNNQjFObFlYUjBiR1V4RXpBUkJnTlZCQWdNQ2xkaGMyaHBibWQwYjI0eElqQWdCZ05WQkFvTUdVRnRZWHB2CmJpQlhaV0lnVTJWeWRtbGpaWE1zSUVsdVl5NHhFekFSQmdOVkJBc01Da0Z0WVhwdmJpQlNSRk14SURBZUJnTlYKQkFNTUYwRnRZWHB2YmlCU1JGTWdVbTl2ZENBeU1ERTVJRU5CTUlJQklqQU5CZ2txaGtpRzl3MEJBUUVGQUFPQwpBUThBTUlJQkNnS0NBUUVBclhuRi9FNi9RaCtrdTNoUVRTS1BNaFFRbENwb1d2bkl0aHpYNk1LM3A1YTBlWEtaCm9XSWpZY05ORzZVd0pqcDRmVVhsNmdscDUzSm9ibit0V05YODhkTkgybjhEVmJwcFN3U2NWRTJMcHVMKzk0dlkKMEVZRS9YeE43c3ZLZWE4WXZscnFrVUJLeXhMeFRqaCtVL0tyR09hSHh6OXYwbDZaTmxEYnVhWnczcUlXZEQvSQo2YU5iR2VSVVZ0cE02UCtiV0lveFZsL2NhUXlsUVM2Q0VZVWsrQ3BWeUpTa29wd0pselhUMDd0TW9ETDVXZ1g5Ck8wOEtWZ0ROejlxUC9JR3RBY1JkdVJjTmlvSDNFOXY5ODFRTzF6dC9HcGIyZjhOcUFqVVVDVVp6T25pajZteDkKTWNaKzljV1g4OENSelIwdlFPRFd1WnNjZ0kwOE52TTY5Rm4yU1FJREFRQUJvMk13WVRBT0JnTlZIUThCQWY4RQpCQU1DQVFZd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVWMxOWcyTHpMQTVqMEt4YzBMalphCnBtRC92Qjh3SHdZRFZSMGpCQmd3Rm9BVWMxOWcyTHpMQTVqMEt4YzBMalphcG1EL3ZCOHdEUVlKS29aSWh2Y04KQVFFTEJRQURnZ0VCQUhBRzdXVG15anpQUklNODVyVmorZldIc0xJdnFwdzZET2JJak1Xb2twbGlDZU1JTlpGVgp5bmZnQktzZjFFeHdidkpOellGWFc2ZGlobmd1REc5Vk1QcGkydXAvY3RRVE44dG05bkRLT3kwOHVOWm9vZk1jCk5VWnhLQ0VrVktaditJTDRvSG9lYXl0OGVndHYzdWpKTTZWMTRBc3RNUTZTd3Z3dkE5M0VQL1VnMmU0V0FYSHUKY2JJMU5BYlVnVkRxcCtEUmRmdlprZ1lLcnlqVFdkLzArMWZTOFgxYkJaVld6bDdlaXJOVm5IYlNIMlpEcE51WQowU0JkOGRqNUY2bGQzdDU4eWRaYnJUSHplN0pKT2Q4aWp5U0FwNC9raXU5VWZaV3VUUEFCekRhL0RTZHo5RGsvCnpQVzRDWFh2aExtRTAyVEE5L0hlQ3czS0VISXdpY051RWZ3PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg=="
          - name: LOG_LEVEL
            value: "error"
          - name: SQS_QUEUE_ARN
            value: "arn:aws:sqs:eu-west-1:000000000000:ReportsGenerator"
          - name: SES_REGION
            value: "eu-west-1"
          - name: SES_FROM
            value: "vulcan@example.com"
          - name: SES_CC
            value: "['vulcan@example.com']"
          - name: SCAN_EMAIL_SUBJECT
            value: "Security Overview"
          - name: SCAN_S3_PUBLIC_BUCKET
            value: "s3-vulcan-public-insights"
          - name: SCAN_S3_PRIVATE_BUCKET
            value: "s3-vulcan-insights"
          - name: SCAN_GA_ID
            value: "UA-109338366-3"
          - name: SCAN_COMPANY_NAME
            value: "Example"
          - name: SCAN_SUPPORT_EMAIL
            value: "vulcan@example.com"
          - name: SCAN_CONTACT_EMAIL
            value: "vulcan@example.com"
          - name: SCAN_CONTACT_CHANNEL
            value: "https://www.slack.com/archives/XXXXX"
          - name: SCAN_CONTACT_JIRA
            value: "https://jira.com/"
          - name: SCAN_DOCS_API_LINK
            value: "https://www.domain.com/org/vulcan-api/examples/#how-do-i-list-the-members-of-a-team"
          - name: SCAN_DOCS_ROADMAP_LINK
            value: "https://docs.google.com/spreadsheets/d/xxxxxxxxxxxxxxx/edit?usp=sharing"
          - name: PERSISTENCE_ENDPOINT  # We keep this PERSISTENCE variable for compatibility
            value: "http://myrelease-vulcan-scanengine"
          - name: RESULTS_ENDPOINT
            value: "http://myrelease-vulcan-results"
          - name: SCAN_PROXY_ENDPOINT
            value: "https://insights.vulcan.example.com"
          - name: VULCAN_UI
            value: "https://www.vulcan.example.com/"
          - name: SCAN_VIEW_REPORT
            value: "https://www.vulcan.example.com/api/v1/report?team_id=%s&scan_id=%s"
          - name: LIVEREPORT_EMAIL_SUBJECT
            value: "Vulcan Digest"
          
          - name: DOGSTATSD_ENABLED
            value: "true"
          - name: DOGSTATSD_HOST
            value: "localhost"
          - name: DOGSTATSD_PORT
            value: "8125"
          envFrom:
          - secretRef:
              name: myrelease-vulcan-reportsgenerator
          ports:
            - name: app
              containerPort: 8080
              protocol: TCP
      volumes:
      - name: config-proxy
        configMap:
          name: myrelease-vulcan-reportsgenerator-proxy
      
      imagePullSecrets:
        - name: pullsecretname
---
# Source: vulcan/templates/results/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myrelease-vulcan-results
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: results
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: vulcan
      app.kubernetes.io/name: results
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vulcan
        global-label: foo
        global-namespace: 'ns'
        app.kubernetes.io/name: results
      annotations:
        checksum/config-proxy: 1ab1794c792ff40d2a263b396ee55459ffcb3a468803823f6eaaf51ad71870f2
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9101'
        iam.amazonaws.com/role: arn:aws:iam::000000000000:role/ResultsRole
    spec:
      containers:
        
        - name: dogstatsd
          image: "datadog/dogstatsd:7.32.3"
          envFrom:
          - secretRef:
              name: myrelease-vulcan-dogstatsd
          ports:
            - containerPort: 8125
              name: dogstatsd
              protocol: UDP
        - name: proxy
          image: "haproxy:2.3.16-alpine3.15"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9090
            - name: metrics
              containerPort: 9101
          volumeMounts:
          - mountPath: /usr/local/etc/haproxy
            readOnly: true
            name: config-proxy
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
        - name: results
          
          image: "adevinta/vulcan-results:tag-results"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          livenessProbe:
            httpGet:
              path: /healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 10
          readinessProbe:
            httpGet:
              path: /healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 5
          env:
          - name: PORT
            value: "8080"
          - name: DEBUG
            value: "false"
          - name: AWS_REGION
            value: "eu-west-1"
          - name: BUCKET_REPORTS
            value: "s3-vulcan-reports"
          - name: BUCKET_LOGS
            value: "s3-vulcan-logs"
          - name: LINK_BASE
            value: "https://results.vulcan.example.com/v1"
          
          - name: DOGSTATSD_ENABLED
            value: "true"
          - name: DOGSTATSD_HOST
            value: "localhost"
          - name: DOGSTATSD_PORT
            value: "8125"
          ports:
            - name: app
              containerPort: 8080
              protocol: TCP
      volumes:
      - name: config-proxy
        configMap:
          name: myrelease-vulcan-results-proxy
      
      imagePullSecrets:
        - name: pullsecretname
---
# Source: vulcan/templates/scanengine/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myrelease-vulcan-scanengine
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: scanengine
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: vulcan
      app.kubernetes.io/name: scanengine
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vulcan
        global-label: foo
        global-namespace: 'ns'
        app.kubernetes.io/name: scanengine
      annotations:
        checksum/secrets: 9550935d782fd7007d686b9fc5ef0d7e0be0fac738f4dea1f8e57c89cb2abbce
        checksum/config-proxy: d4d387927cf4ecc28093ff3b73457832709359dc4e8b98c83484b672e382abac
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9101'
        iam.amazonaws.com/role: arn:aws:iam::000000000000:role/ScanEngineRole
    spec:
      initContainers:
        - name: waitfordb
          image: "busybox:1.34.1"
          imagePullPolicy: Always
          command: ['sh', '-c', 'until nc -z "$PGHOST" "$PGPORT"; do echo WaitingDB && sleep 5; done;']
          env:
          - name: PGHOST
            value: "scanengine.postgres.host"
          - name: PGPORT
            value: "5432"
      containers:
        
        - name: dogstatsd
          image: "datadog/dogstatsd:7.32.3"
          envFrom:
          - secretRef:
              name: myrelease-vulcan-dogstatsd
          ports:
            - containerPort: 8125
              name: dogstatsd
              protocol: UDP
        - name: proxy
          image: "haproxy:2.3.16-alpine3.15"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9090
            - name: metrics
              containerPort: 9101
          volumeMounts:
          - mountPath: /usr/local/etc/haproxy
            readOnly: true
            name: config-proxy
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
        - name: scanengine
          
          image: "adevinta/vulcan-scan-engine:tag-scanengine"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          livenessProbe:
            httpGet:
              path: /v1/healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 10
          readinessProbe:
            httpGet:
              path: /v1/healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 5
          env:
          - name: PORT
            value: "8080"
          - name: PG_HOST
            value: "scanengine.postgres.host"
          - name: PG_NAME
            value: "vulcanscanengine"
          - name: PG_USER
            value: "vulcan"
          - name: PG_PORT
            value: "5432"
          - name: PG_SSLMODE
            value: "verify-full"
          - name: PG_CA_B64
            value: "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVCakNDQXU2Z0F3SUJBZ0lKQU1jMFp6YVNVSzUxTUEwR0NTcUdTSWIzRFFFQkN3VUFNSUdQTVFzd0NRWUQKVlFRR0V3SlZVekVRTUE0R0ExVUVCd3dIVTJWaGRIUnNaVEVUTUJFR0ExVUVDQXdLVjJGemFHbHVaM1J2YmpFaQpNQ0FHQTFVRUNnd1pRVzFoZW05dUlGZGxZaUJUWlhKMmFXTmxjeXdnU1c1akxqRVRNQkVHQTFVRUN3d0tRVzFoCmVtOXVJRkpFVXpFZ01CNEdBMVVFQXd3WFFXMWhlbTl1SUZKRVV5QlNiMjkwSURJd01Ua2dRMEV3SGhjTk1Ua3cKT0RJeU1UY3dPRFV3V2hjTk1qUXdPREl5TVRjd09EVXdXakNCanpFTE1Ba0dBMVVFQmhNQ1ZWTXhFREFPQmdOVgpCQWNNQjFObFlYUjBiR1V4RXpBUkJnTlZCQWdNQ2xkaGMyaHBibWQwYjI0eElqQWdCZ05WQkFvTUdVRnRZWHB2CmJpQlhaV0lnVTJWeWRtbGpaWE1zSUVsdVl5NHhFekFSQmdOVkJBc01Da0Z0WVhwdmJpQlNSRk14SURBZUJnTlYKQkFNTUYwRnRZWHB2YmlCU1JGTWdVbTl2ZENBeU1ERTVJRU5CTUlJQklqQU5CZ2txaGtpRzl3MEJBUUVGQUFPQwpBUThBTUlJQkNnS0NBUUVBclhuRi9FNi9RaCtrdTNoUVRTS1BNaFFRbENwb1d2bkl0aHpYNk1LM3A1YTBlWEtaCm9XSWpZY05ORzZVd0pqcDRmVVhsNmdscDUzSm9ibit0V05YODhkTkgybjhEVmJwcFN3U2NWRTJMcHVMKzk0dlkKMEVZRS9YeE43c3ZLZWE4WXZscnFrVUJLeXhMeFRqaCtVL0tyR09hSHh6OXYwbDZaTmxEYnVhWnczcUlXZEQvSQo2YU5iR2VSVVZ0cE02UCtiV0lveFZsL2NhUXlsUVM2Q0VZVWsrQ3BWeUpTa29wd0pselhUMDd0TW9ETDVXZ1g5Ck8wOEtWZ0ROejlxUC9JR3RBY1JkdVJjTmlvSDNFOXY5ODFRTzF6dC9HcGIyZjhOcUFqVVVDVVp6T25pajZteDkKTWNaKzljV1g4OENSelIwdlFPRFd1WnNjZ0kwOE52TTY5Rm4yU1FJREFRQUJvMk13WVRBT0JnTlZIUThCQWY4RQpCQU1DQVFZd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVWMxOWcyTHpMQTVqMEt4YzBMalphCnBtRC92Qjh3SHdZRFZSMGpCQmd3Rm9BVWMxOWcyTHpMQTVqMEt4YzBMalphcG1EL3ZCOHdEUVlKS29aSWh2Y04KQVFFTEJRQURnZ0VCQUhBRzdXVG15anpQUklNODVyVmorZldIc0xJdnFwdzZET2JJak1Xb2twbGlDZU1JTlpGVgp5bmZnQktzZjFFeHdidkpOellGWFc2ZGlobmd1REc5Vk1QcGkydXAvY3RRVE44dG05bkRLT3kwOHVOWm9vZk1jCk5VWnhLQ0VrVktaditJTDRvSG9lYXl0OGVndHYzdWpKTTZWMTRBc3RNUTZTd3Z3dkE5M0VQL1VnMmU0V0FYSHUKY2JJMU5BYlVnVkRxcCtEUmRmdlprZ1lLcnlqVFdkLzArMWZTOFgxYkJaVld6bDdlaXJOVm5IYlNIMlpEcE51WQowU0JkOGRqNUY2bGQzdDU4eWRaYnJUSHplN0pKT2Q4aWp5U0FwNC9raXU5VWZaV3VUUEFCekRhL0RTZHo5RGsvCnpQVzRDWFh2aExtRTAyVEE5L0hlQ3czS0VISXdpY051RWZ3PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg=="
          - name: LOG_LEVEL
            value: "error"
          - name: PERSISTENCE_HOST
            value: "myrelease-vulcan-persistence"
          - name: CHECKS_SQS_ARN
            value: "arn:aws:sqs:eu-west-1:000000000000:ScanEngineCheckStatus"
          - name: SCANS_SNS_ARN
            value: "arn:aws:sns:eu-west-1:000000000000:Scans"
          - name: CHECKS_SNS_ARN
            value: "arn:aws:sns:eu-west-1:000000000000:Checks"
          - name: STREAM_URL
            value: "http://myrelease-vulcan-stream"
          - name: CHECKS_CREATOR_WORKERS
            value: "3"
          - name: CHECKS_CREATOR_PERIOD
            value: "30"
          - name: QUEUES_DEFAULT_ARN
            value: "arn:aws:sqs:eu-west-1:000000000000:V2ChecksGeneric"
          - name: "QUEUES_1_ARN"
            value: "arn:aws:sqs:eu-west-1:000000000000:V2ChecksTenable"
          - name: "QUEUES_1_CHECKTYPES"
            value: "[\"vulcan-nessus\"]"
          - name: "QUEUES_2_ARN"
            value: "arn:aws:sqs:eu-west-1:000000000000:V2ChecksBurp"
          - name: "QUEUES_2_CHECKTYPES"
            value: "[\"vulcan-burp\"]"
          - name: "QUEUES_3_ARN"
            value: "arn:aws:sqs:eu-west-1:000000000000:V2ChecksBurp"
          - name: "QUEUES_3_CHECKTYPES"
            value: "[]"
          
          - name: DOGSTATSD_ENABLED
            value: "true"
          - name: DOGSTATSD_HOST
            value: "localhost"
          - name: DOGSTATSD_PORT
            value: "8125"
          envFrom:
          - secretRef:
              name: myrelease-vulcan-scanengine
          ports:
            - name: app
              containerPort: 8080
              protocol: TCP
      volumes:
      - name: config-proxy
        configMap:
          name: myrelease-vulcan-scanengine-proxy
      
      imagePullSecrets:
        - name: pullsecretname
---
# Source: vulcan/templates/sqsexporter/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myrelease-vulcan-sqsexporter
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: sqsexporter
    app.kubernetes.io/name: sqsexporter
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: vulcan
      app.kubernetes.io/name: sqsexporter
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vulcan
        global-label: foo
        global-namespace: 'ns'
        app.kubernetes.io/name: sqsexporter
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: "8080"
        iam.amazonaws.com/role: arn:aws:iam::000000000000:role/SQSExporterRole
    spec:
      containers:
        - name: sqsexporter
          
          image: "jesusfcr/sqs-prometheus-exporter:0.4.0"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          env:
          - name: PORT
            value: "8080"
          - name: SQS_QUEUE_NAME_PREFIX
            value: VulcanK8S
          - name: AWS_REGION
            value: "eu-west-1"
          
          
          ports:
            - name: metrics
              containerPort: 8080
              protocol: TCP
      
      imagePullSecrets:
        - name: pullsecretname
---
# Source: vulcan/templates/stream/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myrelease-vulcan-stream
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: stream
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: vulcan
      app.kubernetes.io/name: stream
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vulcan
        global-label: foo
        global-namespace: 'ns'
        app.kubernetes.io/name: stream
      annotations:
        checksum/secrets: f49244775e1fa8f7941498d5b8cc2b7d4f3b36023ce0a2d1013271cc2383e24a
        checksum/config-proxy: 5049bfc1fcffbd83ea2447c039f055995e19008206936d52be1a7e3e1037644d
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9101'
        iam.amazonaws.com/role: arn:aws:iam::000000000000:role/StreamRole
    spec:
      containers:
        
        - name: dogstatsd
          image: "datadog/dogstatsd:7.32.3"
          envFrom:
          - secretRef:
              name: myrelease-vulcan-dogstatsd
          ports:
            - containerPort: 8125
              name: dogstatsd
              protocol: UDP
        - name: proxy
          image: "haproxy:2.3.16-alpine3.15"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9090
            - name: metrics
              containerPort: 9101
          volumeMounts:
          - mountPath: /usr/local/etc/haproxy
            readOnly: true
            name: config-proxy
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
        - name: stream
          
          image: "adevinta/vulcan-stream:tag-stream"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          livenessProbe:
            httpGet:
              path: /status
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 10
          readinessProbe:
            httpGet:
              path: /status
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 5
          env:
          - name: PORT
            value: "8080"
          - name: LOG_LEVEL
            value: "DEBUG"
          - name: REDIS_HOST
            value: "myelasticcache"
          - name: REDIS_USR
            value: ""
          - name: REDIS_PORT
            value: "6379"
          - name: REDIS_DB
            value: "0"
          - name: REDIS_TTL
            value: "0"
          
          - name: DOGSTATSD_ENABLED
            value: "true"
          - name: DOGSTATSD_HOST
            value: "localhost"
          - name: DOGSTATSD_PORT
            value: "8125"
          envFrom:
          - secretRef:
              name: myrelease-vulcan-stream
          ports:
            - name: app
              containerPort: 8080
              protocol: TCP
      volumes:
      - name: config-proxy
        configMap:
          name: myrelease-vulcan-stream-proxy
      
      imagePullSecrets:
        - name: pullsecretname
---
# Source: vulcan/templates/ui/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myrelease-vulcan-ui
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ui
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: vulcan
      app.kubernetes.io/name: ui
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vulcan
        global-label: foo
        global-namespace: 'ns'
        app.kubernetes.io/name: ui
      annotations:
        checksum/config-proxy: a8e3f609fa8f5b852963fd1acee44e70b9a1f9dfe868c6fb40dfb541a94a6520
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9101'
    spec:
      containers:
        
        - name: proxy
          image: "haproxy:2.3.16-alpine3.15"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9090
            - name: metrics
              containerPort: 9101
          volumeMounts:
          - mountPath: /usr/local/etc/haproxy
            readOnly: true
            name: config-proxy
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
        - name: ui
          
          image: "adevinta/vulcan-ui:tag-vulcan-ui"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          livenessProbe:
            httpGet:
              path: /index.html
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 10
          readinessProbe:
            httpGet:
              path: /index.html
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 5
          env:
          - name: PORT
            value: "8080"
          - name: API_URL
            value: "https://www.vulcan.example.com/api/v1/"
          - name: UI_DOCS_API_LINK
            value: "https://docs.erxample.com/security/vulcan-api/"
          - name: UI_DOCS_WHITELISTING_LINK
            value: "https://docs.example.com/security/vulcan-docs/network-access/"
          - name: UI_DOCS_DISCOVERY_LINK
            value: "https://docs.example.com/security/vulcan-docs/60-asset-auto-discovery/"
          - name: UI_DOCS_AUDITROLE_LINK
            value: "https://confluence.example.com/x/code"
          - name: UI_CONTACT_EMAIL
            value: "vulcan@example.com"
          - name: UI_CONTACT_SLACK
            value: "https://org.slack.com/archives/XXXXXXXXXXXX"
          
          
          ports:
            - name: app
              containerPort: 8080
              protocol: TCP
      volumes:
      - name: config-proxy
        configMap:
          name: myrelease-vulcan-ui-proxy
      
      imagePullSecrets:
        - name: pullsecretname
---
# Source: vulcan/templates/vulndb/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myrelease-vulcan-vulndb
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vulndb
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: vulcan
      app.kubernetes.io/name: vulndb
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vulcan
        global-label: foo
        global-namespace: 'ns'
        app.kubernetes.io/name: vulndb
      annotations:
        checksum/secrets: 39549d2baf1f3ecacbfd06c388f09188b436a3a4b21dea2860caad1ac7136f12
        
        iam.amazonaws.com/role: arn:aws:iam::000000000000:role/VulnDBRole
    spec:
      initContainers:
        - name: waitfordb
          image: "busybox:1.34.1"
          imagePullPolicy: Always
          command: ['sh', '-c', 'until nc -z "$PGHOST" "$PGPORT"; do echo WaitingDB && sleep 5; done;']
          env:
          - name: PGHOST
            value: "vulnerabilitydb.postgres.host"
          - name: PGPORT
            value: "5432"
      containers:
        
        - name: vulndb
          
          image: "adevinta/vulnerability-db:tag-vulndb"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          env:
          - name: PG_HOST
            value: "vulnerabilitydb.postgres.host"
          - name: PG_NAME
            value: "vulnerabilitydb"
          - name: PG_USER
            value: "vulnerabilitydb"
          - name: PG_PORT
            value: "5432"
          - name: PG_SSLMODE
            value: "verify-full"
          - name: PG_CA_B64
            value: "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVCakNDQXU2Z0F3SUJBZ0lKQU1jMFp6YVNVSzUxTUEwR0NTcUdTSWIzRFFFQkN3VUFNSUdQTVFzd0NRWUQKVlFRR0V3SlZVekVRTUE0R0ExVUVCd3dIVTJWaGRIUnNaVEVUTUJFR0ExVUVDQXdLVjJGemFHbHVaM1J2YmpFaQpNQ0FHQTFVRUNnd1pRVzFoZW05dUlGZGxZaUJUWlhKMmFXTmxjeXdnU1c1akxqRVRNQkVHQTFVRUN3d0tRVzFoCmVtOXVJRkpFVXpFZ01CNEdBMVVFQXd3WFFXMWhlbTl1SUZKRVV5QlNiMjkwSURJd01Ua2dRMEV3SGhjTk1Ua3cKT0RJeU1UY3dPRFV3V2hjTk1qUXdPREl5TVRjd09EVXdXakNCanpFTE1Ba0dBMVVFQmhNQ1ZWTXhFREFPQmdOVgpCQWNNQjFObFlYUjBiR1V4RXpBUkJnTlZCQWdNQ2xkaGMyaHBibWQwYjI0eElqQWdCZ05WQkFvTUdVRnRZWHB2CmJpQlhaV0lnVTJWeWRtbGpaWE1zSUVsdVl5NHhFekFSQmdOVkJBc01Da0Z0WVhwdmJpQlNSRk14SURBZUJnTlYKQkFNTUYwRnRZWHB2YmlCU1JGTWdVbTl2ZENBeU1ERTVJRU5CTUlJQklqQU5CZ2txaGtpRzl3MEJBUUVGQUFPQwpBUThBTUlJQkNnS0NBUUVBclhuRi9FNi9RaCtrdTNoUVRTS1BNaFFRbENwb1d2bkl0aHpYNk1LM3A1YTBlWEtaCm9XSWpZY05ORzZVd0pqcDRmVVhsNmdscDUzSm9ibit0V05YODhkTkgybjhEVmJwcFN3U2NWRTJMcHVMKzk0dlkKMEVZRS9YeE43c3ZLZWE4WXZscnFrVUJLeXhMeFRqaCtVL0tyR09hSHh6OXYwbDZaTmxEYnVhWnczcUlXZEQvSQo2YU5iR2VSVVZ0cE02UCtiV0lveFZsL2NhUXlsUVM2Q0VZVWsrQ3BWeUpTa29wd0pselhUMDd0TW9ETDVXZ1g5Ck8wOEtWZ0ROejlxUC9JR3RBY1JkdVJjTmlvSDNFOXY5ODFRTzF6dC9HcGIyZjhOcUFqVVVDVVp6T25pajZteDkKTWNaKzljV1g4OENSelIwdlFPRFd1WnNjZ0kwOE52TTY5Rm4yU1FJREFRQUJvMk13WVRBT0JnTlZIUThCQWY4RQpCQU1DQVFZd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVWMxOWcyTHpMQTVqMEt4YzBMalphCnBtRC92Qjh3SHdZRFZSMGpCQmd3Rm9BVWMxOWcyTHpMQTVqMEt4YzBMalphcG1EL3ZCOHdEUVlKS29aSWh2Y04KQVFFTEJRQURnZ0VCQUhBRzdXVG15anpQUklNODVyVmorZldIc0xJdnFwdzZET2JJak1Xb2twbGlDZU1JTlpGVgp5bmZnQktzZjFFeHdidkpOellGWFc2ZGlobmd1REc5Vk1QcGkydXAvY3RRVE44dG05bkRLT3kwOHVOWm9vZk1jCk5VWnhLQ0VrVktaditJTDRvSG9lYXl0OGVndHYzdWpKTTZWMTRBc3RNUTZTd3Z3dkE5M0VQL1VnMmU0V0FYSHUKY2JJMU5BYlVnVkRxcCtEUmRmdlprZ1lLcnlqVFdkLzArMWZTOFgxYkJaVld6bDdlaXJOVm5IYlNIMlpEcE51WQowU0JkOGRqNUY2bGQzdDU4eWRaYnJUSHplN0pKT2Q4aWp5U0FwNC9raXU5VWZaV3VUUEFCekRhL0RTZHo5RGsvCnpQVzRDWFh2aExtRTAyVEE5L0hlQ3czS0VISXdpY051RWZ3PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg=="
          - name: LOG_LEVEL
            value: "info"
          - name: MAX_EVENT_AGE
            value: "365"
          - name: SQS_QUEUE_ARN
            value: "arn:aws:sqs:eu-west-1:000000000000:VulnDBChecks"
          - name: SNS_TOPIC_ARN
            value: "arn:aws:sns:eu-west-1:000000000000:VulnDBVulns"
          - name: RESULTS_URL
            value: https://results.vulcan.example.com
          - name: RESULTS_INTERNAL_URL
            value: "http://myrelease-vulcan-results"
          
          
          envFrom:
          - secretRef:
              name: myrelease-vulcan-vulndb
      volumes:
      
      
      imagePullSecrets:
        - name: pullsecretname
---
# Source: vulcan/templates/vulndbapi/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myrelease-vulcan-vulndbapi
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: vulndbapi
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: vulcan
      app.kubernetes.io/name: vulndbapi
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: vulcan
        global-label: foo
        global-namespace: 'ns'
        app.kubernetes.io/name: vulndbapi
      annotations:
        checksum/secrets: 13017ca8bd1bcc0ea59177896eb26dbb39ac5cde736cc1f39c0bfcd76fc98da4
        checksum/config-proxy: 208d3aed79e8d756f70c7dce0de18028186b3441c5b8c75d22c31e657920e770
        prometheus.io/scrape: 'true'
        prometheus.io/port: '9101'
    spec:
      initContainers:
        - name: waitfordb
          image: "busybox:1.34.1"
          imagePullPolicy: Always
          command: ['sh', '-c', 'until nc -z "$PGHOST" "$PGPORT"; do echo WaitingDB && sleep 5; done;']
          env:
          - name: PGHOST
            value: "vulnerabilitydb.postgres.host"
          - name: PGPORT
            value: "5432"
      containers:
        
        - name: proxy
          image: "haproxy:2.3.16-alpine3.15"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9090
            - name: metrics
              containerPort: 9101
          volumeMounts:
          - mountPath: /usr/local/etc/haproxy
            readOnly: true
            name: config-proxy
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
        - name: vulndbapi
          
          image: "adevinta/vulnerability-db-api:tag-vulndb-api"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","sleep 30;"]
          livenessProbe:
            httpGet:
              path: /healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 10
          readinessProbe:
            httpGet:
              path: /healthcheck
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 5
          env:
          - name: PORT
            value: "8080"
          - name: PG_HOST
            value: "vulnerabilitydb.postgres.host"
          - name: PG_NAME
            value: "vulnerabilitydb"
          - name: PG_USER
            value: "vulnerabilitydb"
          - name: PG_PORT
            value: "5432"
          - name: PG_SSLMODE
            value: "verify-full"
          - name: PG_CA_B64
            value: "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUVCakNDQXU2Z0F3SUJBZ0lKQU1jMFp6YVNVSzUxTUEwR0NTcUdTSWIzRFFFQkN3VUFNSUdQTVFzd0NRWUQKVlFRR0V3SlZVekVRTUE0R0ExVUVCd3dIVTJWaGRIUnNaVEVUTUJFR0ExVUVDQXdLVjJGemFHbHVaM1J2YmpFaQpNQ0FHQTFVRUNnd1pRVzFoZW05dUlGZGxZaUJUWlhKMmFXTmxjeXdnU1c1akxqRVRNQkVHQTFVRUN3d0tRVzFoCmVtOXVJRkpFVXpFZ01CNEdBMVVFQXd3WFFXMWhlbTl1SUZKRVV5QlNiMjkwSURJd01Ua2dRMEV3SGhjTk1Ua3cKT0RJeU1UY3dPRFV3V2hjTk1qUXdPREl5TVRjd09EVXdXakNCanpFTE1Ba0dBMVVFQmhNQ1ZWTXhFREFPQmdOVgpCQWNNQjFObFlYUjBiR1V4RXpBUkJnTlZCQWdNQ2xkaGMyaHBibWQwYjI0eElqQWdCZ05WQkFvTUdVRnRZWHB2CmJpQlhaV0lnVTJWeWRtbGpaWE1zSUVsdVl5NHhFekFSQmdOVkJBc01Da0Z0WVhwdmJpQlNSRk14SURBZUJnTlYKQkFNTUYwRnRZWHB2YmlCU1JGTWdVbTl2ZENBeU1ERTVJRU5CTUlJQklqQU5CZ2txaGtpRzl3MEJBUUVGQUFPQwpBUThBTUlJQkNnS0NBUUVBclhuRi9FNi9RaCtrdTNoUVRTS1BNaFFRbENwb1d2bkl0aHpYNk1LM3A1YTBlWEtaCm9XSWpZY05ORzZVd0pqcDRmVVhsNmdscDUzSm9ibit0V05YODhkTkgybjhEVmJwcFN3U2NWRTJMcHVMKzk0dlkKMEVZRS9YeE43c3ZLZWE4WXZscnFrVUJLeXhMeFRqaCtVL0tyR09hSHh6OXYwbDZaTmxEYnVhWnczcUlXZEQvSQo2YU5iR2VSVVZ0cE02UCtiV0lveFZsL2NhUXlsUVM2Q0VZVWsrQ3BWeUpTa29wd0pselhUMDd0TW9ETDVXZ1g5Ck8wOEtWZ0ROejlxUC9JR3RBY1JkdVJjTmlvSDNFOXY5ODFRTzF6dC9HcGIyZjhOcUFqVVVDVVp6T25pajZteDkKTWNaKzljV1g4OENSelIwdlFPRFd1WnNjZ0kwOE52TTY5Rm4yU1FJREFRQUJvMk13WVRBT0JnTlZIUThCQWY4RQpCQU1DQVFZd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVWMxOWcyTHpMQTVqMEt4YzBMalphCnBtRC92Qjh3SHdZRFZSMGpCQmd3Rm9BVWMxOWcyTHpMQTVqMEt4YzBMalphcG1EL3ZCOHdEUVlKS29aSWh2Y04KQVFFTEJRQURnZ0VCQUhBRzdXVG15anpQUklNODVyVmorZldIc0xJdnFwdzZET2JJak1Xb2twbGlDZU1JTlpGVgp5bmZnQktzZjFFeHdidkpOellGWFc2ZGlobmd1REc5Vk1QcGkydXAvY3RRVE44dG05bkRLT3kwOHVOWm9vZk1jCk5VWnhLQ0VrVktaditJTDRvSG9lYXl0OGVndHYzdWpKTTZWMTRBc3RNUTZTd3Z3dkE5M0VQL1VnMmU0V0FYSHUKY2JJMU5BYlVnVkRxcCtEUmRmdlprZ1lLcnlqVFdkLzArMWZTOFgxYkJaVld6bDdlaXJOVm5IYlNIMlpEcE51WQowU0JkOGRqNUY2bGQzdDU4eWRaYnJUSHplN0pKT2Q4aWp5U0FwNC9raXU5VWZaV3VUUEFCekRhL0RTZHo5RGsvCnpQVzRDWFh2aExtRTAyVEE5L0hlQ3czS0VISXdpY051RWZ3PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg=="
          - name: LOG_LEVEL
            value: "info"
          
          
          envFrom:
          - secretRef:
              name: myrelease-vulcan-vulndbapi
          ports:
            - name: app
              containerPort: 8080
              protocol: TCP
      volumes:
      - name: config-proxy
        configMap:
          name: myrelease-vulcan-vulndbapi-proxy
      
      imagePullSecrets:
        - name: pullsecretname
---
# Source: vulcan/templates/api/hpa.yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: myrelease-vulcan-api
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: api
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myrelease-vulcan-api
  minReplicas: 1
  maxReplicas: 5
  metrics:
    - type: Resource
      resource:
        name: cpu
        targetAverageUtilization: 50
---
# Source: vulcan/templates/insights/hpa.yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: myrelease-vulcan-insights
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: insights
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myrelease-vulcan-insights
  minReplicas: 1
  maxReplicas: 5
  metrics:
    - type: Resource
      resource:
        name: cpu
        targetAverageUtilization: 50
---
# Source: vulcan/templates/persistence/hpa.yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: myrelease-vulcan-persistence
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: persistence
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myrelease-vulcan-persistence
  minReplicas: 1
  maxReplicas: 5
  metrics:
    - type: Resource
      resource:
        name: cpu
        targetAverageUtilization: 50
---
# Source: vulcan/templates/results/hpa.yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: myrelease-vulcan-results
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: results
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myrelease-vulcan-results
  minReplicas: 1
  maxReplicas: 5
  metrics:
    - type: Resource
      resource:
        name: cpu
        targetAverageUtilization: 50
---
# Source: vulcan/templates/scanengine/hpa.yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: myrelease-vulcan-scanengine
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: scanengine
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myrelease-vulcan-scanengine
  minReplicas: 1
  maxReplicas: 5
  metrics:
    - type: Resource
      resource:
        name: cpu
        targetAverageUtilization: 50
---
# Source: vulcan/templates/api/ingress.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: myrelease-vulcan-api
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: api
  annotations:
    certmanager.k8s.io/cluster-issuer: letsencrypt
    nginx.ingress.kubernetes.io/cors-allow-origin: https://www.vulcan.example.com
    nginx.ingress.kubernetes.io/enable-cors: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: 8m
spec:
  tls:
    - hosts:
        - "www.vulcan.example.com"
      secretName: vulcan-api-tls
  rules:
    - host: "www.vulcan.example.com"
      http:
        paths:
          - path: /api
            backend:
              serviceName: myrelease-vulcan-api
              servicePort: 80
---
# Source: vulcan/templates/insights/ingress.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: myrelease-vulcan-insights
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: insights
  annotations:
    certmanager.k8s.io/cluster-issuer: letsencrypt
    nginx.ingress.kubernetes.io/configuration-snippet: |
      more_set_headers "X-Frame-Options: SAMEORIGIN";
      more_set_headers "X-Content-Type-Options: nosniff";
      more_set_headers "X-Frame-Options: DENY";
      more_set_headers "X-Xss-Protection: 1";
      more_set_headers "Strict-Transport-Security: max-age=31536000; includeSubDomains";
      more_set_headers "Content-Security-Policy: default-src 'none'; script-src 'self' 'unsafe-inline' https://insights.vulcan.example.com https://www.google-analytics.com; font-src 'self' https://insights.vulcan.example.com; connect-src 'self' https://insights.vulcan.example.com; img-src 'self' https://insights.vulcan.example.com https://www.google-analytics.com; style-src 'self' 'unsafe-inline' https://insights.vulcan.example.com; object-src 'none'";
    nginx.ingress.kubernetes.io/cors-allow-origin: '*'
    nginx.ingress.kubernetes.io/enable-cors: "true"
spec:
  tls:
    - hosts:
        - "insights.vulcan.example.com"
      secretName: vulcan-insights-tls
  rules:
    - host: "insights.vulcan.example.com"
      http:
        paths:
          - path: /
            backend:
              serviceName: myrelease-vulcan-insights
              servicePort: 80
---
# Source: vulcan/templates/persistence/ingress.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: myrelease-vulcan-persistence
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: persistence
  annotations:
    certmanager.k8s.io/cluster-issuer: letsencrypt
    nginx.ingress.kubernetes.io/proxy-body-size: 8m
spec:
  tls:
    - hosts:
        - "persistence.vulcan.example.com"
      secretName: vulcan-persistence-tls
  rules:
    - host: "persistence.vulcan.example.com"
      http:
        paths:
          - path: /
            backend:
              serviceName: myrelease-vulcan-persistence
              servicePort: 80
---
# Source: vulcan/templates/results/ingress.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: myrelease-vulcan-results
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: results
  annotations:
    certmanager.k8s.io/cluster-issuer: letsencrypt
    nginx.ingress.kubernetes.io/proxy-body-size: 8m
spec:
  tls:
    - hosts:
        - "results.vulcan.example.com"
      secretName: vulcan-results-tls
  rules:
    - host: "results.vulcan.example.com"
      http:
        paths:
          - path: /
            backend:
              serviceName: myrelease-vulcan-results
              servicePort: 80
---
# Source: vulcan/templates/stream/ingress.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: myrelease-vulcan-stream
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: stream
  annotations:
    certmanager.k8s.io/cluster-issuer: letsencrypt
    nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
spec:
  tls:
    - hosts:
        - "stream.vulcan.example.com"
      secretName: vulcan-stream-tls
  rules:
    - host: "stream.vulcan.example.com"
      http:
        paths:
          - path: /
            backend:
              serviceName: myrelease-vulcan-stream
              servicePort: 80
---
# Source: vulcan/templates/ui/ingress.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: myrelease-vulcan-ui
  labels:
    helm.sh/chart: vulcan-0.4.0
    app.kubernetes.io/instance: vulcan
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: ui
  annotations:
    certmanager.k8s.io/cluster-issuer: letsencrypt
spec:
  tls:
    - hosts:
        - "www.vulcan.example.com"
      secretName: vulcan-ui-tls
  rules:
    - host: "www.vulcan.example.com"
      http:
        paths:
          - path: /
            backend:
              serviceName: myrelease-vulcan-ui
              servicePort: 80
