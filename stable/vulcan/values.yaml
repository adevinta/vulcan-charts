# Default values for vulcan.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
global:
  domain: vulcan.local
  region: local
  minio:
    enabled: true
  goaws:
    accountId: "012345678900"
  sns:
    enabled: true
  sqs:
    enabled: true
  postgresql:
    enabled: true

postgresql:
  enabled: true
  postgresqlUsername: postgres
  postgresqlPassword: TBD
  postgresqlDatabase: persistence
  initdbScripts:
    initial-dbs.sql: |
      CREATE DATABASE api;
      CREATE DATABASE scanengine;
      CREATE DATABASE reportsgenerator;
      CREATE DATABASE vulnerabilitydb;
  master:
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9187"
  resources:
    requests:
      cpu: "0"
      memory: "0"
  persistence:
    enabled: false
  metrics:
    enabled: true

goaws:
  containerPort: 8080
  config:
    goaws.yaml: |
      Local:
        Host: {{ .Release.Name }}-goaws
        Port: {{ .Values.containerPort }}
        AccountId: "{{ .Values.global.goaws.accountId }}"
        LogToFile: false
        QueueAttributeDefaults:
          VisibilityTimeout: 30
          ReceiveMessageWaitTimeSeconds: 0
        Queues:
          - Name: VulcanK8SAPIScans
          - Name: VulcanK8SChecksGeneric
          - Name: VulcanK8SChecksTenable
          - Name: VulcanK8SMetricsChecks
          - Name: VulcanK8SMetricsScans
          - Name: VulcanK8SMetricsFindings
          - Name: VulcanK8SScanEngineChecks
          - Name: VulcanK8SReportsGenerator
          - Name: VulcanK8SPersistenceChecks
          - Name: VulcanK8SVulnDBChecks
        Topics:
          - Name: VulcanK8SChecks
            Subscriptions:
              - QueueName: VulcanK8SMetricsChecks
                Raw: true
              - QueueName: VulcanK8SScanEngineChecks
                Raw: true
                #FilterPolicy: '{"foo": ["bar"]}'
          - Name: VulcanK8SScans
            Subscriptions:
              - QueueName: VulcanK8SAPIScans
                Raw: true
              - QueueName: VulcanK8SMetricsScans
                Raw: true
          - Name: VulcanK8SReportsGen
            Subscriptions:
              - QueueName: VulcanK8SReportsGenerator
                Raw: true
          - Name: VulcanK8SScanEngineChecks
            Subscriptions:
              - QueueName: VulcanK8SPersistenceChecks
                Raw: true
          - Name: VulcanK8SVulnDBVulns
              - QueueName: VulcanK8SMetricsFindings
                Raw: true
        RandomLatency:
          Min: 0
          Max: 0

minio:
  enabled: true
  mode: standalone
  defaultBuckets: "reports,logs,scans,insights,public-insights,crontinuous"
  serviceAccount:
    create: false
  persistence:
    enabled: false
  service:
    port: 80
    type: NodePort    # To bypass problem with minio.chart
  accessKey:
    password: AKIAIOSFODNN7EXAMPLE
  secretKey:
    password: "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
  extraEnv:
    - name: MINIO_REGION_NAME
      value: local

defaults:
  db: &db
    user: postgres
    password: TBD
    sslMode: disable
  common:  &common
    proxy: &proxy
      enabled: true
      image:
        repository: haproxy
        tag: 2.2-alpine
      port: 9090  # We use non 80 port to prevent prometheus trying to access metrics on port 80
      cache:
        enabled: false
        maxSize: 64 # mb
        maxAge: 240 # seconds
      probe: false
      probePath: /healthz
      probeInitialDelay: 5
      probeTimeoutSeconds: 3
      # timeoutConnect: 5s
      # timeoutClient: 25s
      # timeoutServer: 25s
      # timeoutTunnel: 3600s
      lifecycle:
        preStopSleep: 30
      resources: {}
    dogstatsd: &dogstatsd
      image: 
        repository: datadog/dogstatsd
        tag: 7.25.1

  # Default values for all the components
  comp: &comp

    <<: *common
    replicaCount:
    image:
      pullPolicy: Always

    podSecurityContext: {}

    securityContext: {}

    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 5
      targetCPUUtilizationPercentage: 50
      targetMemoryUtilizationPercentage: 50

    imagePullSecrets: []
    nameOverride: ""
    fullnameOverride: ""
    containerPort: 8080

    livenessProbe: &comp-livenessProbe
      enabled: true
      path: /healthcheck
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 3
      successThreshold: 1
      failureThreshold: 10

    readinessProbe: &comp-readynessProbe
      enabled: true
      path: /healthcheck
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 3
      successThreshold: 1
      failureThreshold: 5

    service:
      type: ClusterIP
      port: 80

    ingress:
      enabled: false
      annotations: {}
        # kubernetes.io/ingress.class: nginx
        # kubernetes.io/tls-acme: "true"
      hosts:
        - host: chart-example.local
          paths: []
      tls: []
      #  - secretName: chart-example-tls
      #    hosts:
      #      - chart-example.local

    resources: {}
    nodeSelector: {}
    tolerations: []
    affinity: {}


results:
  enabled: true
  name: results
  <<: *comp

  image:
    repository: adevinta/vulcan-results
    tag: latest
    pullPolicy: Always

  conf:
    debug: "false"
    region:
    bucketReports: reports
    bucketLogs: logs
    linkBase: http://chart-example.local

  lifecycle:
    preStopSleep: 30

  livenessProbe:
    <<: *comp-livenessProbe
    path: /healthcheck

  readinessProbe:
    <<: *comp-readynessProbe
    path: /healthcheck

  infra:
    s3: true

  # extraEnv:
  #   FOO: BAR


persistence:
  enabled: true
  name: persistence
  <<: *comp

  image:
    repository: adevinta/vulcan-persistence
    tag: latest
    pullPolicy: Always

  waitfordb:
    image:
      repository: postgres
      tag: 9.6-alpine

  lifecycle:
    preStopSleep: 30
    # preStopCommand:  '["/bin/sh", "-c", "/app/stop.sh 30"]'
  terminationGracePeriodSeconds: 60

  livenessProbe:
    <<: *comp-livenessProbe
    path: /status

  readinessProbe:
    <<: *comp-readynessProbe
    path: /status

  infra:
    s3: true
    sns: true
    sqs: true

  db:
    <<: *db
    name: persistence

  conf:
    logLevel: warn
    snsTopic: arn:aws:sns:local:012345678900:VulcanK8SChecks
    nessusCheckQueue: VulcanK8SChecksTenable
    s3Scans: scans
    # awsCreateChecksSqsUrl: https://localhost/012345678900/VulcanK8SPersistenceChecks
    awsCreateChecksSqsName: VulcanK8SPersistenceChecks
    secretKeyBase: TBDTBD
    channel: events
    railsMaxThreads: 4
    awsCreateChecksWorkers: 4

  # extraEnv:
  #   FOO: BAR


stream:
  enabled: true
  name: stream
  <<: *comp

  image:
    repository: adevinta/vulcan-stream
    tag: latest
    pullPolicy: Always

  waitfordb:
    image:
      repository: postgres
      tag: 9.6-alpine

  lifecycle:
    preStopSleep: 30

  livenessProbe:
    <<: *comp-livenessProbe
    path: /status

  readinessProbe:
    <<: *comp-readynessProbe
    path: /status

  conf:
    logLevel: "DEBUG"
    redis:
      host: TBD
      port: TDB
      usr: TBD
      pwd: TBD
      db: 0   # default
      ttl: 0  # default

  # extraEnv:
  #   FOO: BAR


api:
  enabled: true
  name: api
  <<: *comp

  image:
    repository: adevinta/vulcan-api
    tag: latest
    pullPolicy: Always

  waitfordb:
    image:
      repository: postgres
      tag: 9.6-alpine

  infra:
    sqs: true
    sns: true
    s3: true

  lifecycle:
    preStopSleep: 30

  livenessProbe:
    <<: *comp-livenessProbe
    path: /api/v1/healthcheck

  readinessProbe:
    <<: *comp-readynessProbe
    path: /api/v1/healthcheck

  db:
    <<: *db
    name: api

  conf:
    debug: "false"
    bucketReports: reports
    bucketLogs: logs
    s3PrivateBucket: insights
    s3PublicBucket: public-insights
    queueArn: arn:aws:sqs:local:012345678900:VulcanK8SAPIScans
    queueName: VulcanK8SAPIScans
    reports:
      snsArn: arn:aws:sns:local:012345678900:VulcanK8SReportsGen
      redirectUrl:
      vulcanUIUrl:
    secretKey: TBDTBD
    cookieDomain:     # default .Values.global.domain
    saml:
      metadata: https://okta/app/TBD/sso/saml/metadata
      issuer: http://okta/TBD
      callback: # https://vulcan-api/api/v1/login/callback
      trustedDomains: '[]'  # '["vulcan-api"]'
    log:
      level: INFO
    defaultOwners: '[]'  # '["owner1","owner2"]'
    vulndbapiUrl: # http://vulnerabilitydbapi
    persistenceHost:
    crontinuousUrl:
    reportsgeneratorUrl:
    scanengineUrl:
    apiHostname:
    awscatalogue:
      kind: None
      url: http://catalogue.example.com
      key: key
      retries: 1
      retry_interval: 2

  # extraEnv:
  #   FOO: BAR

  ingress:
    path: /api


crontinuous:
  enabled: true
  name: crontinuous
  <<: *comp

  image:
    repository: adevinta/vulcan-crontinuous
    tag: latest
    pullPolicy: Always

  infra:
    s3: true

  lifecycle:
    preStopSleep: 30

  livenessProbe:
    <<: *comp-livenessProbe
    path: /healthcheck

  readinessProbe:
    <<: *comp-readynessProbe
    path: /healthcheck

  conf:
    region:
    vulcanToken: TBDTBDTBD
    crontinuousBucket: crontinuous
    vulcanUser: tbd
    vulcanApi:  # http://host/api
    enableTeamsWhitelistScan: "false"
    teamsWhitelistScan: '[]'
    enableTeamsWhitelistReport: "false"
    teamsWhitelistReport: '[]'

  # extraEnv:
  #   FOO: BAR

scanengine:
  enabled: true
  name: scanengine
  <<: *comp

  image:
    repository: adevinta/vulcan-scan-engine
    tag: latest
    pullPolicy: Always

  waitfordb:
    image:
      repository: postgres
      tag: 9.6-alpine

  lifecycle:
    preStopSleep: 30

  livenessProbe:
    <<: *comp-livenessProbe
    path: /v1/healthcheck

  readinessProbe:
    <<: *comp-readynessProbe
    path: /v1/healthcheck

  infra:
    sqs: true
    sns: true

  conf:
    logLevel: "error"
    queueArn: arn:aws:sqs:local:012345678900:VulcanK8SScanEngineChecks
    queueName: VulcanK8SScanEngineChecks
    scansSNS:
      topicArn: arn:aws:sns:local:012345678900:VulcanK8SScans
    checksSNS:
      topicArn: arn:aws:sns:eu-west-1:012345678900:VulcanK8SScanEngineChecks
    queues:
      default:
        arn: VulcanK8SChecksGeneric
      nessus:
        arn: VulcanK8SChecksTenable
        checktypes: '["vulcan-nessus"]'
    persistenceHost:
    streamUrl:
    checkCreator:
      numOfWorkers: 2
      period: 20

  db:
    <<: *db
    name: scanengine


ui:
  <<: *common
  lifecycle:
    preStopSleep: 30
  infra:
    sqs: false

insights:
  enabled: true
  name: insights
  <<: *comp

  global:
    minio:
      enabled: false

  image:
    repository: pottava/s3-proxy
    tag: "2.0"
    pullPolicy: Always

  lifecycle:
    preStopSleep: 30

  livenessProbe:
    <<: *comp-livenessProbe
    path: /healthcheck

  readinessProbe:
    <<: *comp-readynessProbe
    path: /healthcheck

  proxy:
    enabled: true
    <<: *proxy
    metricsPort: 9101
    cache:
      enabled: true

  conf:
    region:
    log: "false"
    proxies:
      - name: private
        s3Bucket: insights
        prefix: ""
      - name: public
        s3Bucket: public-insights
        prefix: "/public"

reportsgenerator:
  <<: *common
  lifecycle:
    preStopSleep: 30
  infra:
    sqs: true
  conf:
    logLevel: "error"
    queueArn: arn:aws:sqs:local:012345678900:VulcanK8SReportsGenerator
    queueName: VulcanK8SReportsGenerator
    generators:
      scan:
        publicBucket: public-insights
        privateBucket: insights
  db:
    <<: *db
    name: reportsgenerator

metrics:
  proxy:
    enabled: false
  infra:
    sqs: true
  dogstatsd:
    <<: *dogstatsd
    enabled: true
  conf:
    checksQueueArn: arn:aws:sqs:local:012345678900:VulcanK8SMetricsChecks
    scansQueueArn: arn:aws:sqs:local:012345678900:VulcanK8SMetricsScans
    findingsQueueArn: arn:aws:sqs:local:012345678900:VulcanK8SMetricsFindings

vulndbapi:
  <<: *common
  lifecycle:
    preStopSleep: 30
  conf:
    logLevel: "error"
  db:
    <<: *db
    name: vulnerabilitydb

vulndb:
  <<: *common
  proxy:
    enabled: false
  infra:
    sqs: true
    sns: true
  conf:
    logLevel: "error"
    checksQueueArn: arn:aws:sqs:local:012345678900:VulcanK8SVulnDBChecks
    vulnsTopicArn: arn:aws:sns:local:012345678900:VulcanK8SVulnDBVulns
  db:
    <<: *db
    name: vulnerabilitydb

sqsExporter:
  enabled: true
  image:
    repository: jesusfcr/sqs-exporter
    tag: custom-endpoint
  queueNamePrefix: VulcanK8S
  resources: {}

dogstatsd:
  apiKey: TBD

# customTplManifests: |
#     apiVersion: v1
#     kind: ConfigMap
#     metadata:
#       labels:
#         {{- include "vulcan.labels" . | nindent 4 }}
#       name: {{ .Release.Name }}-extra
#     data:
#       FOO: var

serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name:

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}
